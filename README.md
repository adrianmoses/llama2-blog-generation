# llama2-blog-generation
Blog Generation with llama2
![](Captura de pantalla 2024-02-04 a las 16.49.16.png)


Using transformers with langchain is very straightforward

Would be cool to use ollama, but ollama is pretty limited on models. Especially compared to HF


Definitely can add this functionality to Blawgsum. But would want to make it RAG supported
and possibly work with an outline if possible

